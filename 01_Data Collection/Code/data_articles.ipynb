{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.select import Select\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (\"changement climatique\" | \"réchauffement climatique\" | \"effet de serre\" )>1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_articles(journal, start, end, times):\n",
    "    \n",
    "    email = 'xianlin.ding@sciencespo.fr'\n",
    "    password = '099115Keep12??'\n",
    "    path = os.getcwd()\n",
    "    path = re.sub('Code','Result',path)\n",
    "    \n",
    "    # go into the Eruopresse website\n",
    "    url = \"https://acces-distant.sciencespo.fr/fork?https://nouveau.europresse.com/access/ip/default.aspx?un=politique2T_1\"\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    driver.get(url)\n",
    "    driver.find_element(By.ID, 'username').send_keys(email)\n",
    "    driver.find_element(By.ID, 'password').send_keys(password)\n",
    "    time.sleep(3)\n",
    "    driver.find_element(By.CLASS_NAME, 'btn-submit').click()\n",
    "    \n",
    "    # choose the criteria of searching\n",
    "    driver.find_element(By.CLASS_NAME, 'lnk-text').click()\n",
    "    time.sleep(3)\n",
    "    driver.find_element(By.ID, 'specific-sources-rd').click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # choose the journal\n",
    "    try:\n",
    "        driver.find_element(By.ID, journal).click()\n",
    "    except:\n",
    "        time.sleep(20)\n",
    "        driver.find_element(By.ID, journal).click()\n",
    "    \n",
    "    # key words : climat and climatique\n",
    "    driver.find_element(By.XPATH, '//textarea').send_keys(\"(\\\"changement climatique\\\" | \\\"réchauffement climatique\\\" | \\\"effet de serre\\\" )>1\") \n",
    "    driver.find_elements(By.CLASS_NAME, 'criteria-oper-lbl')[1].click()\n",
    "    # Select(driver.find_element(By.NAME, 'CriteriaKeys[0].Key')).select_by_value('TEXT')\n",
    "    # driver.find_element(By.NAME, 'CriteriaKeys[0].Text').send_keys('climatique')\n",
    "    \n",
    "    # choose the searching period\n",
    "    Select(driver.find_element(By.ID, 'DateFilter_DateRange')).select_by_value('10')\n",
    "\n",
    "    Select(driver.find_elements(By.CLASS_NAME, 'year')[1]).select_by_value(start[0])\n",
    "    Select(driver.find_elements(By.CLASS_NAME, 'year')[2]).select_by_value(end[0])\n",
    "\n",
    "    Select(driver.find_elements(By.CLASS_NAME, 'month')[1]).select_by_value(start[1])\n",
    "    Select(driver.find_elements(By.CLASS_NAME, 'month')[2]).select_by_value(end[1])\n",
    "\n",
    "    Select(driver.find_elements(By.CLASS_NAME, 'day')[1]).select_by_value(start[2])\n",
    "    Select(driver.find_elements(By.CLASS_NAME, 'day')[2]).select_by_value(end[2])\n",
    "    \n",
    "    driver.find_element(By.ID, 'btnSearch').click()\n",
    "    \n",
    "    # scroll page\n",
    "    for i in range(times):\n",
    "        temp_height=0\n",
    "        while True:\n",
    "            driver.execute_script(\"window.scrollBy(0,1000)\")\n",
    "            check_height = driver.execute_script(\"return document.documentElement.scrollTop || window.pageYOffset || document.body.scrollTop;\")\n",
    "            if check_height==temp_height:\n",
    "                break\n",
    "            temp_height=check_height\n",
    "        \n",
    "        time.sleep(5)\n",
    "        if (i+1) % 5 == 0:\n",
    "            print('scrolling ', i+1, ' times' )\n",
    "        \n",
    "    # get web contents\n",
    "    web_content = driver.page_source\n",
    "    obj = BeautifulSoup(web_content,'lxml').body\n",
    "    obj = obj.aside.ul\n",
    "    obj = obj.find_all(name='div', attrs={\"class\":\"docListItem msDocItem\"})\n",
    "    \n",
    "    # start to build data\n",
    "    info = pd.DataFrame(columns = ['date', 'publication', \n",
    "                                   'words', 'author',\n",
    "                                   'title', 'intro'])\n",
    "    \n",
    "    i=0\n",
    "    for obj_i in obj:\n",
    "        \n",
    "        obj_i = obj_i.div.next_sibling.next_sibling\n",
    "        \n",
    "        # publication\n",
    "        obj_i_1 = obj_i.div\n",
    "        \n",
    "        obj_i_1 = obj_i\n",
    "        \n",
    "        obj_i_1 = obj_i_1.find_all(name='span', attrs={\"class\":\"source-name\"})[0]\n",
    "        obj_i_1 = str(obj_i_1)\n",
    "        publication_i = re.findall(r\"<span class=\\\"source-name\\\">(.+?)</span>\", obj_i_1)[0]\n",
    "        \n",
    "        # title\n",
    "        obj_i_2 = obj_i.div.next_sibling.next_sibling\n",
    "        title_i = obj_i_2.div.a\n",
    "        title_i = str(title_i)\n",
    "        title_i = re.findall(r\">(.+?)</a>\", title_i)[0]\n",
    "        title_i = re.sub('\\u200a','',title_i)\n",
    "        \n",
    "        # date and words\n",
    "        obj_i_3 = obj_i_2.div.next_sibling.next_sibling \n",
    "        \n",
    "        date_words_i = obj_i_3.div\n",
    "        date_words_i = str(date_words_i)\n",
    "        date_words_i = re.sub('\\n','',date_words_i)\n",
    "        date_words_i = re.sub('\\t','',date_words_i)\n",
    "        \n",
    "        date_i = re.findall(r\"<span class=\\\"details\\\">(.+?)<span class=\", date_words_i)[0]\n",
    "        date_i = date_i.replace(' ', '')\n",
    "        \n",
    "        words_i = re.findall(r\"</span>(.+?)</span>\", date_words_i)[0]\n",
    "        words_i = words_i.replace(' ', '')\n",
    "        \n",
    "        # authors and introduction\n",
    "        obj_i_4 = obj_i_3.div.next_sibling.next_sibling\n",
    "        obj_i_4 = str(obj_i_4)\n",
    "        obj_i_4 = re.sub('\\n','',obj_i_4)\n",
    "        obj_i_4 = re.sub('\\t','',obj_i_4)\n",
    "        \n",
    "        try:\n",
    "            obj_i_4 = obj_i_4.split('<span class=\"doclist-author\">')[1]\n",
    "            author_i = obj_i_4.split('</span>')[0]\n",
    "            intro_i = obj_i_4.split('</span>')[1]\n",
    "        \n",
    "        except:\n",
    "            author_i = None\n",
    "            intro_i = obj_i_4.split('</span></span>')[1]\n",
    "    \n",
    "        intro_i = intro_i.split('</div>')[0]\n",
    "        intro_i = re.sub(r\"<([a-z]+)>\",'',intro_i)\n",
    "        intro_i = re.sub(r\"</([a-z]+)>\",'',intro_i)\n",
    "        intro_i = re.sub('\\u200a','',intro_i)\n",
    "        intro_i = re.sub('-','',intro_i)\n",
    "        \n",
    "        info.loc[i] = [date_i, publication_i, \n",
    "                       words_i, author_i,\n",
    "                       title_i, intro_i]\n",
    "        i = i+1\n",
    "    \n",
    "    info_name = str(publication_i) + '_' + \\\n",
    "              str(start[0]) + '_' + \\\n",
    "              str(start[1]) + '_' + str(end[1])\n",
    "    \n",
    "    info.to_csv(path + '\\\\data_raw_v2\\\\'+ info_name + '.csv')\n",
    "    \n",
    "    print('Import Data ' + info_name + 'finished.')\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_period(year):\n",
    "    \n",
    "    start_md = [['1','1'],['5','1'],['9','1']]\n",
    "    end_md = [['4','30'], ['8','31'], ['12','31']]\n",
    "    \n",
    "    start = []\n",
    "    for i in year:    \n",
    "        for j in start_md:\n",
    "            start_ij = []\n",
    "            start_ij.append(i)\n",
    "            start_ij = start_ij + j\n",
    "            start.append(start_ij)\n",
    "            \n",
    "    end = []\n",
    "    for i in year:    \n",
    "        for j in end_md:\n",
    "            end_ij = []\n",
    "            end_ij.append(i)\n",
    "            end_ij = end_ij + j\n",
    "            end.append(end_ij)\n",
    "            \n",
    "    return start,end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now change it into functions\n",
    "def import_data(journal_code, year_list):\n",
    "    \n",
    "    start_list, end_list = generate_period(year_list)\n",
    "    \n",
    "    for i in range(len(year_list)):\n",
    "        for j in range(3):\n",
    "            \n",
    "            journal = journal_code\n",
    "            start = start_list[i*3 + j]\n",
    "            end = end_list[i*3 + j]\n",
    "            times = 10\n",
    "            \n",
    "            while True:\n",
    "                try:\n",
    "                    scrape_articles(journal, start, end, times)\n",
    "                    break\n",
    "                except:\n",
    "                    print('Maximum access times reach, sleep 5 minutes.')\n",
    "                    time.sleep(300)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid missing data during collection, \n",
    "# We split it into several parts \n",
    "# by journals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Le monde\n",
    "\n",
    "journal_code = 'sf_247'\n",
    "year_list = list(map(lambda x:str(x),list(range(2013,2023))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-122-85af4b26b9e6>:10: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2013_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2013_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2013_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2014_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2014_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2014_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2015_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2015_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2015_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2016_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2016_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2016_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2017_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2017_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2017_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2018_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2018_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2018_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2019_1_4finished.\n",
      "Maximum access times reach, sleep 5 minutes.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2019_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2019_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2020_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2020_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2020_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2021_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2021_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2021_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2022_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2022_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Monde_2022_9_12finished.\n"
     ]
    }
   ],
   "source": [
    "import_data(journal_code, year_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Les Echos\n",
    "\n",
    "journal_code = 'sf_251'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|████████████████████████████████████████████████████████| 6.79M/6.79M [00:00<00:00, 9.25MB/s]\n",
      "<ipython-input-3-85af4b26b9e6>:10: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2013_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2013_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2013_9_12finished.\n"
     ]
    }
   ],
   "source": [
    "year_list = list(map(lambda x:str(x),list(range(2013,2014))))\n",
    "import_data(journal_code, year_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-85af4b26b9e6>:10: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2014_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2014_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2014_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2015_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2015_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2015_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2016_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2016_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2016_9_12finished.\n"
     ]
    }
   ],
   "source": [
    "year_list = list(map(lambda x:str(x),list(range(2014,2017))))\n",
    "import_data(journal_code, year_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-85af4b26b9e6>:10: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2017_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2017_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2017_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2018_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2018_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2018_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2019_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2019_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2019_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2020_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2020_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2020_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2021_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2021_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2021_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2022_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2022_5_8finished.\n",
      "Maximum access times reach, sleep 5 minutes.\n",
      "Maximum access times reach, sleep 5 minutes.\n"
     ]
    }
   ],
   "source": [
    "year_list = list(map(lambda x:str(x),list(range(2017,2023))))\n",
    "import_data(journal_code, year_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-85af4b26b9e6>:10: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2022_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2022_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Les Echos_2022_9_12finished.\n"
     ]
    }
   ],
   "source": [
    "year_list = list(map(lambda x:str(x),list(range(2022,2023))))\n",
    "import_data(journal_code, year_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libération\n",
    "\n",
    "journal_code = 'sf_252'\n",
    "year_list = list(map(lambda x:str(x),list(range(2013,2023))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-85af4b26b9e6>:10: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2013_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2013_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2013_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2014_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2014_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2014_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2015_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2015_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2015_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2016_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2016_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2016_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2017_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2017_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2017_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2018_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2018_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2018_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2019_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2019_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2019_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2020_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2020_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2020_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2021_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2021_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2021_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2022_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2022_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Libération_2022_9_12finished.\n"
     ]
    }
   ],
   "source": [
    "import_data(journal_code, year_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## La Croix\n",
    "\n",
    "journal_code = 'sf_243'\n",
    "year_list = list(map(lambda x:str(x),list(range(2013,2023))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-85af4b26b9e6>:10: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2013_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2013_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2013_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2014_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2014_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2014_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2015_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2015_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2015_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2016_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2016_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2016_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2017_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2017_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2017_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2018_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2018_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2018_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2019_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2019_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2019_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2020_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2020_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2020_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2021_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2021_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2021_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2022_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2022_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data La Croix_2022_9_12finished.\n"
     ]
    }
   ],
   "source": [
    "import_data(journal_code, year_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Le Figaro\n",
    "journal_code = 'sf_246'\n",
    "year_list = list(map(lambda x:str(x),list(range(2013,2023))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-85af4b26b9e6>:10: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2013_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2013_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2013_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2014_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2014_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2014_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2015_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2015_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2015_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2016_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2016_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2016_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2017_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2017_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2017_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2018_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2018_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2018_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2019_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2019_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2019_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2020_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2020_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2020_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2021_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2021_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2021_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2022_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2022_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Figaro_2022_9_12finished.\n"
     ]
    }
   ],
   "source": [
    "import_data(journal_code, year_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Le Parisien\n",
    "\n",
    "journal_code = 'sf_257'\n",
    "year_list = list(map(lambda x:str(x),list(range(2013,2023))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-85af4b26b9e6>:10: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien_2013_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien_2013_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien_2013_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien_2014_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien_2014_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien_2014_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien_2015_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien_2015_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien_2015_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien_2016_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien - Paris _2016_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien - Paris _2016_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien - Val d'Oise _2017_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien - Oise_2017_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien - Edition Principale _2017_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien - Paris_2018_1_4finished.\n",
      "Maximum access times reach, sleep 5 minutes.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien - Yvelines_2018_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien - Paris _2018_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien - Val de Marne_2019_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien - Hauts-de-Seine_2019_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien - Seine-et-Marne _2019_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien - Edition Principale _2020_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien - Paris _2020_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien - Oise _2020_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien - Oise _2021_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien - Paris _2021_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien - Paris _2021_9_12finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien - Paris _2022_1_4finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien - Oise _2022_5_8finished.\n",
      "scrolling  5  times\n",
      "scrolling  10  times\n",
      "Import Data Le Parisien - Oise _2022_9_12finished.\n"
     ]
    }
   ],
   "source": [
    "import_data(journal_code, year_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
